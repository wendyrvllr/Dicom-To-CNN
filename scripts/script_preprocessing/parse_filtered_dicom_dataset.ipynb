{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from dicom_to_cnn.tools.cleaning_dicom.folders import *\n",
    "from dicom_to_cnn.tools.pre_processing.series import get_series_object\n",
    "\n",
    "import csv\n",
    "from dicom_to_cnn.model.reader.Series import Series"
   ]
  },
  {
   "source": [
    "#### - Get every serie paths and generate JSON file "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_paths = get_series_path('directory where are dicom files')\n",
    "export_folder = 'where to write json'"
   ]
  },
  {
   "source": [
    "index_problem = []\n",
    "for serie_path in series_paths:\n",
    "    print(series_paths.index(serie_path))\n",
    "    try:\n",
    "        dicom_serie = get_series_object(serie_path)\n",
    "        dicomsInfo = dicom_serie.get_series_details()\n",
    "        write_json_file(export_folder, dicomsInfo['series']['SeriesInstanceUID'], dicomsInfo)\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        print(dicomsInfo)\n",
    "        index_problem.append(series_paths.index(serie_path))"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dir_json = os.listdir(export_folder)\n",
    "dataset = []\n",
    "for file_ in list_dir_json : \n",
    "    dataset.append([os.path.join(export_folder, file_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "source": [
    "#### - Get informations from every json in list "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for patient in dataset : \n",
    "    with open(patient[0]) as json_file : \n",
    "        reader = json.load(json_file)\n",
    "        patient_id = reader[\"patient\"][\"PatientID\"]\n",
    "        study_uid = reader[\"study\"]['StudyInstanceUID']\n",
    "        modal = reader['series']['Modality']\n",
    "        path = reader['path']\n",
    "        type_ = reader['study'][\"StudyDescription\"] #has to be PET0, PET2 for example\n",
    "        patient.append(path)\n",
    "        patient.append(modal)\n",
    "        patient.append(type_)\n",
    "        patient.append(patient_id)\n",
    "        patient.append(study_uid)\n",
    "\n",
    "#each patient : [json_file, path of the serie, modality of the serie, type_, patient_id, study_uid] value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "source": [
    "#### - Reunite CT/PT series with same study uid "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get every study_uid \n",
    "study_uid = []\n",
    "for patient in dataset :\n",
    "    if patient[-1] not in study_uid : \n",
    "        study_uid.append(patient[-1]) \n",
    "print('Number of study_uid :', len(study_uid))\n",
    "\n",
    "reunited_series = []\n",
    "for uid in study_uid : \n",
    "    sub = []\n",
    "    for patient in dataset : \n",
    "        if uid in patient : \n",
    "            sub.append(patient)\n",
    "    reunited_series.append(sub)\n",
    "#reunited_series = [ [uid 1 : [serie_1], [serie_2]], [uid 2 : [serie_1], [serie_2]], ...]\n",
    "dataset = []\n",
    "for study in reunited_series : \n",
    "    if len(study) == 2 : #a CT and PET series\n",
    "        study[0].append(study[1][0])#json_path \n",
    "        study[0].append(study[1][1])#path \n",
    "        study[0].append(study[1][2])#modal \n",
    "    dataset.append(study[0])\n",
    "#dataset = [ [json_path_1, path_serie_1, modal_1, type_1, patient_id, study_uid, json_path_2, path_serie_2, modal_2]]"
   ]
  },
  {
   "source": [
    "#### Clean dataset : double study_uid, if not CT AND PT"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check double study_uid \n",
    "dataset = [x for n, x in enumerate(dataset) if x not in dataset[:n]]\n",
    "print('dataset cleaned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check Modality \n",
    "index = []\n",
    "for patient in dataset : \n",
    "    modal = []\n",
    "    modal.append(patient[2])\n",
    "    modal.append(patient[-1])\n",
    "    if modal[0] == modal[1] : \n",
    "        index.append(dataset.index(patient)) #put in index list the index of patient in dataset which have double modality\n",
    "if len(index) != 0 : #if there is existing index, remove patient from dataset \n",
    "    patient_to_remove = []\n",
    "    for ind in index : \n",
    "        patient_to_remove.append(dataset[ind])\n",
    "    for patient in patient_to_remove : \n",
    "        dataset.remove(patient)\n",
    "print(\"dataset cleaned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of study after clean :\", len(dataset))"
   ]
  },
  {
   "source": [
    "#### - Prepare json file to generate nifti in \"nifti_builder_from_json.ipynb\" script"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "study_results = []\n",
    "for patient in dataset: \n",
    "    #patient = [json_path_1, path_serie_1, modal_1, type_1, patient_id, study_uid, json_path_2, path_serie_2, modal_2]\n",
    "    subliste = []\n",
    "    subliste.append(patient[1]) #path_1\n",
    "    subliste.append(patient[2]) #modal 1\n",
    "    subliste.append(patient[-2]) #path_2\n",
    "    subliste.append(patient[-1]) #modal_2\n",
    "    subliste.append(patient[5]) #study_uid\n",
    "    subliste.append(patient[3]) #type\n",
    "    subliste.append(patient[4]) #patient id\n",
    "    study_results.append(subliste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results as json \n",
    "directory = ''\n",
    "filename = 'filename'\n",
    "write_json_file(directory, filename, study_results)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "6a0b6c04207aa6f5c33e08335e377a5793c5a1abe8e179f13df17cfd923ec7d1"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}